# ðŸš€ ç¡¬ä»¶ä¼˜åŒ–å¿«é€Ÿå‚è€ƒå¡

## âœ… ä¼˜åŒ–å®Œæˆæ€»ç»“

### ðŸ“Š å…³é”®é…ç½®å˜æ›´

| å‚æ•° | ä¼˜åŒ–å‰ | ä¼˜åŒ–åŽ | æ”¹è¿› |
|------|--------|--------|------|
| **num_envs** | 12 | 20 | +67% (æ›´å¥½åˆ©ç”¨24æ ¸CPU) |
| **horizon_length** | 512 | 256 | -50% (å†…å­˜èŠ‚çœ) |
| **minibatch_size** | 512 | 1280 | +150% (GPUåˆ©ç”¨çŽ‡) |
| **mini_epochs** | 6 | 8 | +33% (è¡¥å¿æ ·æœ¬æ•°) |
| **learning_rate** | 3e-4 | 5e-4 | +67% (æ›´å¿«æ”¶æ•›) |
| **img_size** | 84Ã—84 | 64Ã—64 | -44% åƒç´  (å†…å­˜èŠ‚çœ) |

### ðŸ’¾ å†…å­˜ä¼˜åŒ–æ•ˆæžœ

```
Experience Buffer: 42.9 MB â†’ 21.3 MB (-50%)
é¢„è®¡ RAM ä½¿ç”¨: 25.9 GB â†’ 15-18 GB (-30%)
å†…å­˜å®‰å…¨ä½™é‡: ~1 GB â†’ ~14 GB (14å€æ”¹è¿›ï¼)
```

### ðŸŽ® GPU ä¼˜åŒ–æ•ˆæžœ

```
Minibatch å¤§å°: 512 â†’ 1280 (+2.5x)
å¹¶è¡Œå›¾åƒå¤„ç†: 512 å¼  84Ã—84 â†’ 1280 å¼  64Ã—64
é¢„æœŸ GPU åˆ©ç”¨çŽ‡: 15% â†’ 40-60% (~3x æå‡)
```

### âš¡ è®­ç»ƒé€Ÿåº¦é¢„æœŸ

```
æ¯æ¬¡è¿­ä»£æ ·æœ¬æ•°: 6,144 â†’ 5,120
æ¢¯åº¦æ›´æ–°æ¬¡æ•°/epoch: 12 â†’ 32 (+2.7x)
æ ·æœ¬åˆ©ç”¨æ•ˆçŽ‡: +2.5x
é¢„æœŸ FPS æå‡: +50-100%
```

## ðŸ”§ ä¿®æ”¹çš„æ–‡ä»¶

1. **configs/config_stage2.yaml**
   - `num_envs: 20`

2. **configs/train/stage2/PPO_Stage2.yaml**
   - `learning_rate: 5e-4`
   - `horizon_length: 256`
   - `minibatch_size: 1280`
   - `mini_epochs: 8`

3. **configs/env/DcmmCfg.py**
   - `img_size = 64`

4. **gym_dcmm/envs/stage2/DcmmVecEnvStage2.py**
   - `self.img_width = 64`
   - `self.img_height = 64`

5. **gym_dcmm/algs/ppo_dcmm/stage2/ModelsStage2.py**
   - æ›´æ–° DepthCNN å…¨è¿žæŽ¥å±‚: `nn.Linear(32*4*4, 256)`
   - æ›´æ–°é»˜è®¤å€¼: `depth_pixels=64*64, img_size=64`

## ðŸš¦ å¯åŠ¨è®­ç»ƒ

```bash
# æ¸…ç†æ—§æ•°æ®ï¼ˆå¯é€‰ï¼‰
rm -rf wandb/run-*

# å¯åŠ¨è®­ç»ƒ
python train_stage2.py

# åœ¨å¦ä¸€ä¸ªç»ˆç«¯ç›‘æŽ§ GPU
watch -n 1 nvidia-smi

# åœ¨å¦ä¸€ä¸ªç»ˆç«¯ç›‘æŽ§å†…å­˜
htop
```

## ðŸ“ˆ ç›‘æŽ§æŒ‡æ ‡

### å…³é”®æ€§èƒ½æŒ‡æ ‡ (WandB)
- `performance/EnvStepFPS` > 2000 âœ…
- `performance/RLTrainFPS` > 1000 âœ…
- `episode_rewards/mean` åº”ç¨³å®šå¢žé•¿
- `losses/entropy` åº” > 0.005 (é˜²æ­¢è¿‡æ—©æ”¶æ•›)

### ç¡¬ä»¶ç›‘æŽ§ (nvidia-smi & htop)
- **GPU åˆ©ç”¨çŽ‡**: 40-60% âœ…
- **GPU å†…å­˜**: < 6 GB âœ…
- **RAM ä½¿ç”¨**: < 20 GB âœ…
- **CPU ä½¿ç”¨**: 70-85% âœ…

## âš ï¸ æ•…éšœæŽ’æŸ¥

### å¦‚æžœå†…å­˜æº¢å‡º (OOM)
```yaml
# é™ä½ŽçŽ¯å¢ƒæ•°
num_envs: 16  # ä»Ž 20 â†’ 16

# æˆ–é™ä½Ž horizon
horizon_length: 128  # ä»Ž 256 â†’ 128
minibatch_size: 512  # ç›¸åº”è°ƒæ•´
```

### å¦‚æžœ GPU åˆ©ç”¨çŽ‡ä»ä½Ž (<30%)
```yaml
# å¢žåŠ  minibatch
minibatch_size: 2048  # ä»Ž 1280 â†’ 2048
# æ³¨æ„: batch_size (5120) å¿…é¡»èƒ½è¢« minibatch_size æ•´é™¤
```

### å¦‚æžœè®­ç»ƒä¸ç¨³å®š
```yaml
# é™ä½Žå­¦ä¹ çŽ‡
learning_rate: 3e-4  # ä»Ž 5e-4 â†’ 3e-4

# å¢žåŠ ç†µç³»æ•°
entropy_coef: 0.02  # ä»Ž 0.01 â†’ 0.02
```

## ðŸŽ¯ ä¼˜åŒ–åŽŸç†

### ä¸ºä»€ä¹ˆå‡å°å›¾åƒå°ºå¯¸æ˜¯å®‰å…¨çš„ï¼Ÿ
- 64Ã—64 è¶³å¤Ÿè¯†åˆ«éšœç¢ç‰©ï¼ˆæ¡Œå­ã€å¢™å£ï¼‰
- CNN æ„Ÿå—é‡Žä¿æŒä¸å˜
- ä¸»è¦æŸå¤±ï¼šè¿œè·ç¦»ç»†èŠ‚ï¼ˆä¸å½±å“æŠ“å–ä»»åŠ¡ï¼‰

### ä¸ºä»€ä¹ˆå‡å°‘ horizon æ˜¯å®‰å…¨çš„ï¼Ÿ
- Catching ä»»åŠ¡æ—¶é•¿: ~2-5ç§’ @ 50Hz = 100-250 steps
- Horizon=256 æä¾› 5.12 ç§’çª—å£ï¼Œè¶³å¤Ÿè¦†ç›–å®Œæ•´æŠ“å–
- GAE (Î»=0.95) æœ‰æ•ˆè·¨åº¦çº¦ 20 steps << 256

### ä¸ºä»€ä¹ˆå¢žå¤§ minibatch èƒ½æå‡ GPUï¼Ÿ
- GPU æ“…é•¿å¹¶è¡Œè®¡ç®—
- æ›´å¤§æ‰¹æ¬¡ â†’ æ›´é«˜ CUDA æ ¸å¿ƒå ç”¨çŽ‡
- æ‰¹å½’ä¸€åŒ–ã€å·ç§¯æ“ä½œçš„å¹¶è¡Œåº¦æå‡

### ä¸ºä»€ä¹ˆå¢žåŠ  mini_epochsï¼Ÿ
- è¡¥å¿è¾ƒçŸ­ horizon å¸¦æ¥çš„æ ·æœ¬æ•°å‡å°‘
- æ¯æ‰¹æ•°æ®è¢«é‡å¤ä½¿ç”¨ 8 æ¬¡
- æé«˜æ ·æœ¬åˆ©ç”¨æ•ˆçŽ‡ï¼Œå‡å°‘çŽ¯å¢ƒäº¤äº’æˆæœ¬

## ðŸ“ æŠ€æœ¯ç»†èŠ‚

### CNN ç»´åº¦è®¡ç®— (64Ã—64)
```
Input: (B, 1, 64, 64)
Conv1 (8,stride=4): (64-8)/4+1 = 15 â†’ (B, 32, 15, 15)
Conv2 (4,stride=2): (15-4)/2+1 = 6  â†’ (B, 64, 6, 6)
Conv3 (3,stride=1): (6-3)/1+1 = 4   â†’ (B, 32, 4, 4)
Flatten: (B, 512)
Linear: (B, 256)
```

### æ‰¹æ¬¡å¤§å°æ•°å­¦
```
batch_size = num_envs Ã— horizon_length
           = 20 Ã— 256 = 5120

num_minibatches = batch_size / minibatch_size
                = 5120 / 1280 = 4

total_updates_per_epoch = num_minibatches Ã— mini_epochs
                        = 4 Ã— 8 = 32 æ¬¡æ¢¯åº¦æ›´æ–°
```

### å†…å­˜åˆ†é…è¯¦è§£
```
Experience Buffer (ä¸»è¦æ¶ˆè€—):
  - Depth (uint8): 256 Ã— 20 Ã— 4096 Ã— 1 = 20.0 MB
  - State (float32): 256 Ã— 20 Ã— 35 Ã— 4 = 0.7 MB
  - Actions (float32): 256 Ã— 20 Ã— 20 Ã— 4 = 0.4 MB
  - Values, Rewards, etc: ~0.2 MB
  - æ€»è®¡: ~21.3 MB

MuJoCo çŽ¯å¢ƒ (20 ä¸ª):
  - æ¯ä¸ªçŽ¯å¢ƒ ~100 MB â†’ 2 GB

PyTorch æ¨¡åž‹:
  - å‚æ•°: ~50 MB
  - ä¼˜åŒ–å™¨çŠ¶æ€: ~100 MB
  - ç¼“å­˜: ~500 MB

é¢„è®¡æ€»è®¡: 15-18 GB (å®‰å…¨ä½™é‡ 14 GB)
```

## âœ¨ é¢„æœŸæ”¹è¿›

- âœ… **å†…å­˜ç“¶é¢ˆè§£é™¤**: 81% â†’ 50% ä½¿ç”¨çŽ‡
- âœ… **GPU å……åˆ†åˆ©ç”¨**: 15% â†’ 50% åˆ©ç”¨çŽ‡
- âœ… **è®­ç»ƒé€Ÿåº¦æå‡**: é¢„è®¡ +50-100% FPS
- âœ… **CPU æ›´å¥½åˆ©ç”¨**: 54% â†’ 75% åˆ©ç”¨çŽ‡
- âœ… **ç³»ç»Ÿç¨³å®šæ€§**: ä¸å†é¢‘ç¹æŽ¥è¿‘å†…å­˜ä¸Šé™

---
**ç”Ÿæˆæ—¶é—´**: 2025-12-09  
**éªŒè¯è„šæœ¬**: `python validate_optimization.py`  
**è¯¦ç»†æŠ¥å‘Š**: `reports/2025-12-09_Hardware_Optimization.md`

